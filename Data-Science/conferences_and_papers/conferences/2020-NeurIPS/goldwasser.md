Invited Talk:
Robustness, Verification, Privacy: Addressing Machine Learning Adversaries
Shafi Goldwasser
https://neurips.cc/virtual/2020/protected/invited_16163.html

Abstract: We will present cryptography inspired models and results to address three challenges that emerge when worst-case adversaries enter the machine learning landscape. These challenges include verification of machine learning models given limited access to good data, training at scale on private training data, and robustness against adversarial examples controlled by worst case adversaries.

Bullet points:
* 0:36:15 California Bail Bill 25 about using risque assessment ML instead of bail; people distrustful not only because they do not trust in algorithm, but also because of verification and because they do not want to hand-over important procedures/rights to machine decisions
* PAC-verifiability paper -> see screenshot
* important: verification needs to be cheaper than training
* 1:02: privacy -> see screenshot
* GWAS = genome wide association study
* homomorphic encryption  
